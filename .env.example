# Port used by the server
PORT=4000

# Log level, set to "trace" for detailed logs
LOG_LEVEL=info

# Secret used by the server to encrypt/decrypt values
# You can use `$ openssl rand -base64 32` to generate new one
CRYPTO_CIPHER_KEY=

# MongoDB database, must be a replica set, see https://www.mongodb.com/docs/manual/tutorial/deploy-replica-set/
MONGODB_URL=mongodb://localhost:27017/?replicaSet=rs0
MONGODB_DATABASE_NAME=bee-api
MONGODB_CA_CERT=

# Redis database, used by distributed queue and as pub/sub broker
REDIS_URL=redis://127.0.0.1:6379/0
REDIS_CA_CERT=

# Redis database for data caching
# In production, make sure you set up eviction policy to `volatile-lru`
# https://redis.io/docs/latest/develop/reference/eviction/#eviction-policies
REDIS_CACHE_URL=redis://127.0.0.1:6379/1
REDIS_CACHE_CA_CERT=

# Object Storage used for files and their text extractions
S3_ENDPOINT=http://127.0.0.1:9000
S3_ACCESS_KEY_ID=minioadmin
S3_SECRET_ACCESS_KEY=minioadmin
S3_BUCKET_FILE_STORAGE=bee-api

# OAuth2 client credentials for access token validation, acting as the resource server
AUTH_WELL_KNOWN=http://127.0.0.1:4001/.well-known/openid-configuration
AUTH_CLIENT_ID=dummy
AUTH_CLIENT_SECRET=dummy
AUTH_AUDIENCE=bee-test

# Remove this in production
AUTH_SERVER_PORT=4001

# Queue workers
RUN_BULLMQ_WORKERS=runs,runs-cleanup,vectorStores-cleanup,vectorStores-fileProcessor,files-extraction-node,files-extraction-python,threads-cleanup,files-cleanup


# --- BACKEND SECTION ---

# LLM backend, possible values are: ollama, openai, watsonx, bam, ibm-vllm
LLM_BACKEND=watsonx

# Embedding backend, possible values are: ollama, openai, watsonx, bam, caikit
EMBEDDING_BACKEND=watsonx

# Extraction backend, possible values are: docling, unstructured-opensource, unstructured-api
EXTRACTION_BACKEND=docling

# --- Backend details (only applicable to backend(s) selected above) ---

# https://ollama.com/
OLLAMA_URL=

# https://openai.com/
OPENAI_API_KEY=

# https://www.ibm.com/products/watsonx-ai
WATSONX_API_KEY=
WATSONX_PROJECT_ID=
WATSONX_REGION=

BAM_API_KEY=

# Must contain port, can contain {model_id} placeholder, e.g. "{model_id}.inference.example.com:443"
IBM_VLLM_URL=
IBM_VLLM_ROOT_CERT=
IBM_VLLM_CERT_CHAIN=
IBM_VLLM_PRIVATE_KEY=

CAIKIT_URL=
CAIKIT_CA_CERT=
CAIKIT_CERT=
CAIKIT_KEY=

UNSTRUCTURED_API_URL=
UNSTRUCTURED_API_KEY=

WDU_URL=

# --- BACKEND SECTION ---

# --- TOOLS SECTION ---

# Code Interpreter, see https://github.com/i-am-bee/bee-code-interpreter
BEE_CODE_INTERPRETER_URL=http://localhost:50051
BEE_CODE_INTERPRETER_CA_CERT=
BEE_CODE_INTERPRETER_CERT=
BEE_CODE_INTERPRETER_KEY=
# Storage for code interpreter, possible values are: s3, filesystem
BEE_CODE_INTERPRETER_STORAGE_BACKEND=filesystem
# applicable for s3 storage, uses S3 credential above
BEE_CODE_INTERPRETER_BUCKET_FILE_STORAGE=
# applicable for filesystem storage
BEE_CODE_INTERPRETER_FILE_STORAGE_PATH=../bee-stack/tmp/code-interpreter-storage

# Milvus is used as a vector store for file search tool
MILVUS_HOST=127.0.0.1
MILVUS_PORT=19530
MILVUS_USE_TLS=false
MILVUS_USERNAME=user
MILVUS_PASSWORD=password
MILVUS_DATABASE_NAME=default

# Search tool backend, possible values are: google, duck-duck-go
SEARCH_TOOL_BACKEND=duck-duck-go
# applicable for google search tool
BEE_GOOGLE_SEARCH_API_KEY=
BEE_GOOGLE_SEARCH_CSE_ID=

# Forward proxy for api calling tool
HTTP_PROXY_URL=

# --- TOOLS SECTION ---

# --- OBSERVABILITY SECTION ---
BEE_OBSERVE_API_URL=http://127.0.0.1:4318
BEE_OBSERVE_API_AUTH_KEY=observe-auth-key
# Enable instrumentation
BEE_FRAMEWORK_INSTRUMENTATION_ENABLED=false
# Ignore sensitive keys from collected events data
INSTRUMENTATION_IGNORED_KEYS="apiToken,apiKey,cseId,accessToken,proxy,username,password"

# --- OBSERVABILITY SECTION ---

# Identifiers to be used for seeder and to allocate new users into default organization
IBM_ORGANIZATION_OWNER_ID=org_user_670cc04869ddffe24f4fd70e

OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318
OTEL_SDK_DISABLED=true
